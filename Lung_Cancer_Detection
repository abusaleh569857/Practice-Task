{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5905519,"sourceType":"datasetVersion","datasetId":3391284},{"sourceId":14440980,"sourceType":"datasetVersion","datasetId":9224089}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/abusalehalamkhan/notebook5f7bd23c43?scriptVersionId=290994832\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"!pip install segmentation_models_pytorch -q\n\nimport torch\nimport segmentation_models_pytorch as smp\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport random\nfrom pathlib import Path\nimport cv2\n\n# --- Configuration ---\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\nMODEL_PATH = '/kaggle/input/lung-cancer-segmentation-model/best_model.pth'\nDATA_DIR = Path('/kaggle/input/lung-cancer-segment/val')\n\n# --- 1. Initialize Model ---\nmodel = smp.UnetPlusPlus(\n    encoder_name=\"resnet34\",\n    encoder_weights=None,\n    in_channels=1,\n    classes=1,\n    activation=None\n)\n\n# --- 2. Load Weights ---\ntry:\n    if torch.cuda.is_available():\n        model.load_state_dict(torch.load(MODEL_PATH))\n    else:\n        model.load_state_dict(torch.load(MODEL_PATH, map_location=torch.device('cpu')))\n    \n    model.to(DEVICE)\n    model.eval()\n    print(\"Model loaded successfully.\")\nexcept Exception as e:\n    print(f\"Error loading model: {e}\")\n\n# --- Helper Function ---\ndef get_mask_path(img_path):\n    path_str = str(img_path)\n    if 'data' in path_str:\n        return Path(path_str.replace('data', 'masks'))\n    elif 'images' in path_str:\n        return Path(path_str.replace('images', 'masks'))\n    return Path(path_str.replace('images', 'masks'))\n\n# --- 3. Get Balanced Samples (5 Tumor, 5 Healthy) ---\ndef get_balanced_samples(all_files, n_tumor=5, n_healthy=5):\n    tumor_samples = []\n    healthy_samples = []\n    \n    random.shuffle(all_files)\n    \n    print(\"Searching for balanced samples...\")\n    \n    for img_path in all_files:\n        if len(tumor_samples) >= n_tumor and len(healthy_samples) >= n_healthy:\n            break\n            \n        mask_path = get_mask_path(img_path)\n        try:\n            if mask_path.exists():\n                mask = np.load(mask_path)\n                \n                # Check if tumor exists\n                if mask.max() > 0: \n                    if len(tumor_samples) < n_tumor:\n                        tumor_samples.append(img_path)\n                else:\n                    if len(healthy_samples) < n_healthy:\n                        healthy_samples.append(img_path)\n        except:\n            continue\n            \n    print(f\"Selected: {len(tumor_samples)} Tumor Images & {len(healthy_samples)} Healthy Images.\")\n    return tumor_samples + healthy_samples\n\n# --- 4. Deep Inspection Test ---\ndef test_balanced_inspection():\n    all_files = list(DATA_DIR.glob('**/*.npy'))\n    image_files = [f for f in all_files if 'data' in str(f) or 'images' in str(f)]\n    \n    if not image_files:\n        print(\"No images found.\")\n        return\n\n    # Get 10 balanced samples\n    selected_files = get_balanced_samples(image_files, n_tumor=5, n_healthy=5)\n    \n    print(\"Starting evaluation...\")\n\n    for i, img_path in enumerate(selected_files):\n        try:\n            # Load Data\n            image = np.load(img_path).astype(np.float32)\n            original_image = image.copy()\n            \n            mask_path = get_mask_path(img_path)\n            true_mask = np.load(mask_path).astype(np.float32)\n\n            # Preprocessing\n            if image.max() > image.min():\n                image = (image - image.min()) / (image.max() - image.min())\n            \n            img_t = torch.from_numpy(image).unsqueeze(0).unsqueeze(0).float().to(DEVICE)\n            img_t = (img_t - 0.5) / 0.5\n            \n            # Inference\n            with torch.no_grad():\n                logits = model(img_t)\n                pred_prob = torch.sigmoid(logits).cpu().numpy().squeeze()\n                \n                # Threshold logic (0.15)\n                pred_mask = (pred_prob > 0.15).astype(np.float32)\n\n            # --- Visualization ---\n            plt.figure(figsize=(20, 5))\n            \n            # 1. Original CT\n            plt.subplot(1, 4, 1)\n            plt.imshow(original_image, cmap='gray')\n            plt.title(f\"Sample {i+1}: Input CT\")\n            plt.axis('off')\n            \n            # 2. Ground Truth\n            plt.subplot(1, 4, 2)\n            plt.imshow(true_mask, cmap='gray', vmin=0, vmax=1)\n            gt_status = \"Tumor Present\" if true_mask.max() > 0 else \"Healthy (No Tumor)\"\n            col_gt = \"red\" if true_mask.max() > 0 else \"green\"\n            plt.title(f\"Actual: {gt_status}\", color=col_gt)\n            plt.axis('off')\n            \n            # 3. Heatmap\n            plt.subplot(1, 4, 3)\n            plt.imshow(original_image, cmap='gray')\n            plt.imshow(pred_prob, cmap='jet', alpha=0.6, vmin=0, vmax=1)\n            plt.title(\"AI Confidence Heatmap\", color='blue')\n            plt.axis('off')\n\n            # 4. Final Prediction\n            plt.subplot(1, 4, 4)\n            plt.imshow(original_image, cmap='gray')\n            plt.imshow(pred_mask, cmap='jet', alpha=0.5, vmin=0, vmax=1)\n            \n            # Determine Result Status\n            has_tumor = true_mask.max() > 0\n            pred_tumor = pred_mask.max() > 0\n            \n            if has_tumor and pred_tumor:\n                status = \"✅ True Positive (Correct Detection)\"\n                col = \"green\"\n            elif not has_tumor and not pred_tumor:\n                status = \"✅ True Negative (Correctly Ignored)\"\n                col = \"green\"\n            elif not has_tumor and pred_tumor:\n                status = \"⚠️ False Positive (Wrong Alarm)\"\n                col = \"orange\"\n            else:\n                status = \"❌ False Negative (Missed Tumor)\"\n                col = \"red\"\n\n            plt.title(status, color=col, fontweight='bold')\n            plt.axis('off')\n            \n            plt.tight_layout()\n            plt.show()\n            print(\"-\" * 100)\n            \n        except Exception as e:\n            print(f\"Error: {e}\")\n\n# --- Run ---\ntest_balanced_inspection()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom tqdm.notebook import tqdm\n\n# --- 1. Helper Function: Calculate Dice and IoU ---\ndef compute_dice_iou(pred_mask, true_mask, eps=1e-7):\n    \"\"\"\n    Computes Dice Coefficient and Intersection over Union (IoU).\n    \"\"\"\n    # Flatten the tensors\n    pred_flat = pred_mask.reshape(-1)\n    true_flat = true_mask.reshape(-1)\n    \n    # Calculate intersection\n    intersection = (pred_flat * true_flat).sum()\n    union = pred_flat.sum() + true_flat.sum()\n    \n    # Dice Score formula: 2*TP / (2*TP + FP + FN)\n    dice = (2. * intersection) / (union + eps)\n    \n    # IoU formula: TP / (TP + FP + FN)\n    iou = intersection / (union - intersection + eps)\n    \n    return dice, iou\n\n# --- 2. Evaluation Loop ---\ndef evaluate_model_performance():\n    # Ensure model is in eval mode\n    model.eval()\n    \n    # Get all validation images\n    all_files = list(DATA_DIR.glob('**/*.npy'))\n    image_files = [f for f in all_files if 'data' in str(f) or 'images' in str(f)]\n    \n    if not image_files:\n        print(\"No images found for evaluation.\")\n        return\n\n    dice_scores = []\n    iou_scores = []\n    \n    print(f\"Starting evaluation on {len(image_files)} images...\")\n    \n    with torch.no_grad():\n        for img_path in tqdm(image_files, desc=\"Evaluating\"):\n            try:\n                # Load Ground Truth Mask first\n                mask_path = get_mask_path(img_path)\n                if not mask_path.exists():\n                    continue\n                \n                true_mask = np.load(mask_path).astype(np.float32)\n\n                # Focus evaluation only on images that actually have tumors\n                # (To see how well the model detects existing tumors)\n                if true_mask.max() == 0:\n                    continue\n\n                # Load Image\n                image = np.load(img_path).astype(np.float32)\n                \n                # Preprocessing\n                if image.max() > image.min():\n                    image = (image - image.min()) / (image.max() - image.min())\n                \n                img_t = torch.from_numpy(image).unsqueeze(0).unsqueeze(0).float().to(DEVICE)\n                img_t = (img_t - 0.5) / 0.5\n                \n                # Model Prediction\n                logits = model(img_t)\n                pred_prob = torch.sigmoid(logits)\n                \n                # Using the lower threshold (0.15) as discussed\n                pred_mask = (pred_prob > 0.15).float().cpu().numpy().squeeze()\n                \n                # Compute scores\n                dice, iou = compute_dice_iou(pred_mask, true_mask)\n                dice_scores.append(dice)\n                iou_scores.append(iou)\n                \n            except Exception:\n                continue\n    \n    # --- 3. Final Results ---\n    avg_dice = np.mean(dice_scores)\n    avg_iou = np.mean(iou_scores)\n    \n    print(\"\\n\" + \"=\"*50)\n    print(f\"FINAL EVALUATION REPORT (Tumor Images Only)\")\n    print(\"=\"*50)\n    print(f\"Total Tumor Images Evaluated : {len(dice_scores)}\")\n    print(f\"Average Dice Score           : {avg_dice:.4f} ({avg_dice*100:.2f}%)\")\n    print(f\"Average IoU Score            : {avg_iou:.4f} ({avg_iou*100:.2f}%)\")\n    print(\"=\"*50)\n    \n    # Verdict Logic\n    if avg_dice > 0.60:\n        print(\"RESULT: Excellent Performance (Standard for Medical AI)\")\n    elif avg_dice > 0.40:\n        print(\"RESULT: Good Performance (Acceptable, can be improved)\")\n    else:\n        print(\"RESULT: Needs Improvement (More training required)\")\n\n# --- Run Evaluation ---\nevaluate_model_performance()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}